{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('/Users/viv/Documents/Code/AnomalyDetectionPCADemo')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check current directory\n",
    "import pathlib\n",
    "pathlib.Path.cwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "              V1        V2        V3        V4        V5        V6        V7  \\\n0       0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n1       0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875   \n2       0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n3       0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n4       0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n...          ...       ...       ...       ...       ...       ...       ...   \n284802  0.756448  0.873531  0.666991  0.160317  0.729603  0.236810  0.235393   \n284803  0.945845  0.766677  0.872678  0.219189  0.771561  0.273661  0.265504   \n284804  0.990905  0.764080  0.781102  0.227202  0.783425  0.293496  0.263547   \n284805  0.954209  0.772856  0.849587  0.282508  0.763172  0.269291  0.261175   \n284806  0.949232  0.765256  0.849601  0.229488  0.765632  0.256488  0.274963   \n\n              V8        V9       V10  ...       V21       V22       V23  \\\n0       0.786444  0.475312  0.510600  ...  0.561184  0.522992  0.663793   \n1       0.786298  0.453981  0.505267  ...  0.557840  0.480237  0.666938   \n2       0.788042  0.410603  0.513018  ...  0.565477  0.546030  0.678939   \n3       0.789434  0.414999  0.507585  ...  0.559734  0.510277  0.662607   \n4       0.782484  0.490950  0.524303  ...  0.561327  0.547271  0.663392   \n...          ...       ...       ...  ...       ...       ...       ...   \n284802  0.863749  0.528729  0.598850  ...  0.564920  0.515249  0.680500   \n284803  0.788548  0.482925  0.488530  ...  0.564933  0.553154  0.665619   \n284804  0.792985  0.477677  0.498692  ...  0.565220  0.537005  0.664877   \n284805  0.792671  0.476287  0.500464  ...  0.565755  0.547353  0.663008   \n284806  0.780938  0.479528  0.489782  ...  0.565688  0.540031  0.671029   \n\n             V24       V25       V26       V27       V28    Amount  Class  \n0       0.391253  0.585122  0.394557  0.418976  0.312697  0.005824      0  \n1       0.336440  0.587290  0.446013  0.416345  0.313423  0.000105      0  \n2       0.289354  0.559515  0.402727  0.415489  0.311911  0.014739      0  \n3       0.223826  0.614245  0.389197  0.417669  0.314371  0.004807      0  \n4       0.401270  0.566343  0.507497  0.420561  0.317490  0.002724      0  \n...          ...       ...       ...       ...       ...       ...    ...  \n284802  0.313600  0.658558  0.466291  0.433929  0.329840  0.000030      0  \n284803  0.245298  0.543855  0.360884  0.417775  0.312038  0.000965      0  \n284804  0.468492  0.592823  0.411176  0.416593  0.312585  0.002642      0  \n284805  0.398836  0.545958  0.514746  0.418520  0.315245  0.000389      0  \n284806  0.383420  0.551319  0.291786  0.416466  0.313401  0.008446      0  \n\n[284807 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.935192</td>\n      <td>0.766490</td>\n      <td>0.881365</td>\n      <td>0.313023</td>\n      <td>0.763439</td>\n      <td>0.267669</td>\n      <td>0.266815</td>\n      <td>0.786444</td>\n      <td>0.475312</td>\n      <td>0.510600</td>\n      <td>...</td>\n      <td>0.561184</td>\n      <td>0.522992</td>\n      <td>0.663793</td>\n      <td>0.391253</td>\n      <td>0.585122</td>\n      <td>0.394557</td>\n      <td>0.418976</td>\n      <td>0.312697</td>\n      <td>0.005824</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.978542</td>\n      <td>0.770067</td>\n      <td>0.840298</td>\n      <td>0.271796</td>\n      <td>0.766120</td>\n      <td>0.262192</td>\n      <td>0.264875</td>\n      <td>0.786298</td>\n      <td>0.453981</td>\n      <td>0.505267</td>\n      <td>...</td>\n      <td>0.557840</td>\n      <td>0.480237</td>\n      <td>0.666938</td>\n      <td>0.336440</td>\n      <td>0.587290</td>\n      <td>0.446013</td>\n      <td>0.416345</td>\n      <td>0.313423</td>\n      <td>0.000105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.935217</td>\n      <td>0.753118</td>\n      <td>0.868141</td>\n      <td>0.268766</td>\n      <td>0.762329</td>\n      <td>0.281122</td>\n      <td>0.270177</td>\n      <td>0.788042</td>\n      <td>0.410603</td>\n      <td>0.513018</td>\n      <td>...</td>\n      <td>0.565477</td>\n      <td>0.546030</td>\n      <td>0.678939</td>\n      <td>0.289354</td>\n      <td>0.559515</td>\n      <td>0.402727</td>\n      <td>0.415489</td>\n      <td>0.311911</td>\n      <td>0.014739</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.941878</td>\n      <td>0.765304</td>\n      <td>0.868484</td>\n      <td>0.213661</td>\n      <td>0.765647</td>\n      <td>0.275559</td>\n      <td>0.266803</td>\n      <td>0.789434</td>\n      <td>0.414999</td>\n      <td>0.507585</td>\n      <td>...</td>\n      <td>0.559734</td>\n      <td>0.510277</td>\n      <td>0.662607</td>\n      <td>0.223826</td>\n      <td>0.614245</td>\n      <td>0.389197</td>\n      <td>0.417669</td>\n      <td>0.314371</td>\n      <td>0.004807</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.938617</td>\n      <td>0.776520</td>\n      <td>0.864251</td>\n      <td>0.269796</td>\n      <td>0.762975</td>\n      <td>0.263984</td>\n      <td>0.268968</td>\n      <td>0.782484</td>\n      <td>0.490950</td>\n      <td>0.524303</td>\n      <td>...</td>\n      <td>0.561327</td>\n      <td>0.547271</td>\n      <td>0.663392</td>\n      <td>0.401270</td>\n      <td>0.566343</td>\n      <td>0.507497</td>\n      <td>0.420561</td>\n      <td>0.317490</td>\n      <td>0.002724</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284802</th>\n      <td>0.756448</td>\n      <td>0.873531</td>\n      <td>0.666991</td>\n      <td>0.160317</td>\n      <td>0.729603</td>\n      <td>0.236810</td>\n      <td>0.235393</td>\n      <td>0.863749</td>\n      <td>0.528729</td>\n      <td>0.598850</td>\n      <td>...</td>\n      <td>0.564920</td>\n      <td>0.515249</td>\n      <td>0.680500</td>\n      <td>0.313600</td>\n      <td>0.658558</td>\n      <td>0.466291</td>\n      <td>0.433929</td>\n      <td>0.329840</td>\n      <td>0.000030</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>0.945845</td>\n      <td>0.766677</td>\n      <td>0.872678</td>\n      <td>0.219189</td>\n      <td>0.771561</td>\n      <td>0.273661</td>\n      <td>0.265504</td>\n      <td>0.788548</td>\n      <td>0.482925</td>\n      <td>0.488530</td>\n      <td>...</td>\n      <td>0.564933</td>\n      <td>0.553154</td>\n      <td>0.665619</td>\n      <td>0.245298</td>\n      <td>0.543855</td>\n      <td>0.360884</td>\n      <td>0.417775</td>\n      <td>0.312038</td>\n      <td>0.000965</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>0.990905</td>\n      <td>0.764080</td>\n      <td>0.781102</td>\n      <td>0.227202</td>\n      <td>0.783425</td>\n      <td>0.293496</td>\n      <td>0.263547</td>\n      <td>0.792985</td>\n      <td>0.477677</td>\n      <td>0.498692</td>\n      <td>...</td>\n      <td>0.565220</td>\n      <td>0.537005</td>\n      <td>0.664877</td>\n      <td>0.468492</td>\n      <td>0.592823</td>\n      <td>0.411176</td>\n      <td>0.416593</td>\n      <td>0.312585</td>\n      <td>0.002642</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>0.954209</td>\n      <td>0.772856</td>\n      <td>0.849587</td>\n      <td>0.282508</td>\n      <td>0.763172</td>\n      <td>0.269291</td>\n      <td>0.261175</td>\n      <td>0.792671</td>\n      <td>0.476287</td>\n      <td>0.500464</td>\n      <td>...</td>\n      <td>0.565755</td>\n      <td>0.547353</td>\n      <td>0.663008</td>\n      <td>0.398836</td>\n      <td>0.545958</td>\n      <td>0.514746</td>\n      <td>0.418520</td>\n      <td>0.315245</td>\n      <td>0.000389</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>0.949232</td>\n      <td>0.765256</td>\n      <td>0.849601</td>\n      <td>0.229488</td>\n      <td>0.765632</td>\n      <td>0.256488</td>\n      <td>0.274963</td>\n      <td>0.780938</td>\n      <td>0.479528</td>\n      <td>0.489782</td>\n      <td>...</td>\n      <td>0.565688</td>\n      <td>0.540031</td>\n      <td>0.671029</td>\n      <td>0.383420</td>\n      <td>0.551319</td>\n      <td>0.291786</td>\n      <td>0.416466</td>\n      <td>0.313401</td>\n      <td>0.008446</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284807 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'sample_data'\n",
    "filename = 'creditcardfraud_orig.csv'\n",
    "\n",
    "#dataset = pd.read_csv(os.path.join(data_dir, filename))\n",
    "dataset = pd.read_csv(filename)\n",
    "dataset = dataset.rename(columns = {\"class\": \"Class\"})\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    227451\n",
      "0    227451\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate input features and target\n",
    "y = dataset.Class\n",
    "feature_data = dataset.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=27)\n",
    "\n",
    "# concatenate training data back together\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud_train = train_data[train_data.Class==0]\n",
    "fraud_train = train_data[train_data.Class==1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsamp_train = resample(fraud_train,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud_train), # match number in majority class\n",
    "                          random_state=517) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "train_upsamp = pd.concat([not_fraud_train, fraud_upsamp_train])\n",
    "\n",
    "# check new class counts\n",
    "print(train_upsamp.Class.value_counts())\n",
    "\n",
    "train_upsamp = resample(train_upsamp, n_samples=10*5)\n",
    "\n",
    "X_train = train_upsamp.drop('Class', axis=1)\n",
    "y_train = train_upsamp.Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Scale data for SVM faster\n",
    "mmscaler = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = mmscaler.transform(X_train)\n",
    "X_test = mmscaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM classifier (linear)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9268810786138127\n",
      "Precision: 0.021641966596095037\n",
      "Recall: 0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "#Create linear kernel SVM\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM classifier (Polynomial)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666268740563885\n",
      "Precision: 0.0463009562154001\n",
      "Recall: 0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9797935465749096\n",
      "Precision: 0.07437348423605497\n",
      "Recall: 0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', degree = 2)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM classifier (radial basis function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9670482075769812\n",
      "Precision: 0.04361210877373012\n",
      "Recall: 0.8673469387755102\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}